# Hand Gestureâ€‘Based Metro Booking System

> Touchless, accessible ticketing for metro stations â€” powered by realâ€‘time hand tracking and gesture input.

---

## ğŸš€ Overview

This project prototypes a **contactâ€‘free metro ticket vending interface** that replaces touchscreens with **hand gestures** detected from a standard camera. The goal is to reduce queues, improve hygiene, and make ticketing more accessible for firstâ€‘time/elderly users.

Built as part of an **HCI capstone** (Fall 2021), the system explores interaction design (personas, scenarios, HTA/KLM/Nielsen heuristics) and implements a working demo that maps **simple, learnable gestures** to common ticketing actions.

---

## âœ¨ Key Features

* **Touchless interaction** using a webcam â€” no physical contact with the kiosk
* **Simple gestures** (move â†’ point, twoâ€‘finger tap â†’ click, palm â†’ cancel) for low learning curve
* **Guided flow** for: *From Station â†’ To Station â†’ Ticket Type â†’ Count â†’ Payment â†’ Confirmation*
* **Onâ€‘screen guidance** with gesture hints and clear feedback (cursor, highlights, sound cues)
* **Queueâ€‘friendly**: fast, singleâ€‘path flow minimizes backtracking and decision load

---

## ğŸ§  Gesture Set (MVP)

| Gesture                    | Action              | Notes                                               |
| -------------------------- | ------------------- | --------------------------------------------------- |
| **Index finger point**     | Move cursor / hover | Smooth cursor mapped to fingertip                   |
| **Two fingers up / pinch** | Click / select      | Primary selection gesture (validated in user tests) |
| **Open palm**              | Back / cancel       | Optional; used to go one step back                  |
| **OK sign** (optional)     | Confirm             | Alternative confirm gesture for accessibility       |

> The MVP validates **twoâ€‘finger click** as the most reliable selection action; alternate gestures can be toggled via config.

---

## ğŸ§© System Architecture

```mermaid
flowchart LR
    Camera[Webcam] --> Pre[Frame Preprocessing]
    Pre --> Tracker[Hand & Landmark Tracking]
    Tracker --> Gestures[Gesture Recognition]
    Gestures --> UI[UI Controller]
    UI --> Flow[Metro Booking Flow\n(From â†’ To â†’ Ticket Type â†’ Payment)]
    Flow --> Confirm[Ticket Confirmation]
```

* **Hand Tracking**: Detect hand/keypoints per frame
* **Gesture Recognition**: Classify pose/transitions (e.g., twoâ€‘finger click)
* **UI Controller**: Drive onâ€‘screen cursor, focus, and selection
* **Booking Flow**: Linear steps with clear affordances and guardrails

---

## ğŸ“¦ Tech Stack

* **Python 3.8+**
* **OpenCV** (video capture + drawing)
* **(Optional) MediaPipe Hands** or equivalent landmark detector
* **NumPy** for geometry/math utilities
* **PyAutoGUI / custom UI** for cursor & selections (depending on implementation)

> If your codebase uses different libs, update the list above and the install command below.

---

## ğŸ› ï¸ Setup

```bash
# 1) Clone
git clone https://github.com/<your-username>/Hand-Gesture-based-Metro-Booking-System.git
cd Hand-Gesture-based-Metro-Booking-System

# 2) (Recommended) Create a virtual environment
python -m venv .venv && source .venv/bin/activate   # Windows: .venv\\Scripts\\activate

# 3) Install dependencies
pip install -r requirements.txt

# 4) Run the app (update the entrypoint if different in your repo)
python main.py
```

**Webcam permissions**: Ensure the OS allows camera access for Python.

---

## â–¶ï¸ Using the Prototype

1. Stand \~50â€“70 cm from the camera with good frontal lighting.
2. **Move** your index finger to hover the onâ€‘screen cursor.
3. **Select** with a **twoâ€‘finger gesture** (or pinch) to click.
4. Follow the onâ€‘screen steps: *From* â†’ *To* â†’ *Ticket Type* â†’ *Count* â†’ *Payment*.
5. Use **open palm** to go back; confirm at the final screen.

**Tips**

* Avoid strong backlight; keep background simple.
* Hold gestures steady for \~200â€“300 ms to improve recognition.

---

## ğŸ“ HCI & Usability (from the study)

* **Personas & scenarios**: Firstâ€‘time riders and elders guided by unambiguous steps
* **HTA**: Singleâ€‘path task model minimizes branches and errors
* **KLM estimate**: Handâ€‘gesture flow â‰ˆ **15.3 s** (prototype), validating low overhead compared to touch
* **Heuristic evaluation**: Mapped to Nielsenâ€™s principles (visibility, match to real world, error prevention)
* **User study**: 28 survey responses + 6 interviews; users favored the **twoâ€‘finger click** and clear stepwise guidance

> See the full report in `docs/` for methods, data, and screenshots.

---

## ğŸ—‚ï¸ Suggested Repository Layout

```
Hand-Gesture-based-Metro-Booking-System/
â”œâ”€ src/
â”‚  â”œâ”€ tracker/           # hand detection & landmarks
â”‚  â”œâ”€ gestures/          # gesture classification
â”‚  â”œâ”€ ui/                # screens & cursor controller
â”‚  â””â”€ main.py            # entrypoint
â”œâ”€ assets/               # icons, screenshots, demo gifs
â”œâ”€ docs/
â”‚  â””â”€ report.pdf         # HCI study (this repoâ€™s report)
â”œâ”€ requirements.txt
â””â”€ README.md
```

> If the current code uses different paths, adjust the layout section after pushing this README.

---

## âœ… Testing Checklist

* [ ] Cursor tracks fingertip smoothly (no jitter)
* [ ] Twoâ€‘finger click registers reliably (>90% in good lighting)
* [ ] Every screen reachable with gestures only
* [ ] Back/cancel recovers from mistakes without losing progress
* [ ] Works for both leftâ€‘ and rightâ€‘handed users (toggle if supported)

---

## ğŸ§ª Known Limitations

* Sensitive to **lighting** and **background clutter**
* Very fast motion can cause missed clicks
* Depth/occlusion of fingers reduces landmark quality

---

## ğŸ—ºï¸ Roadmap

* Multiâ€‘language flow and iconâ€‘only mode
* Voice prompts + audio confirmations
* Adjustable sensitivity & dwellâ€‘time settings
* Station search with gesture keyboard
* Accessibility presets (tremorâ€‘friendly clicks)

---

## ğŸ“¸ Screenshots

Add captures to `assets/` and reference them here:

| Home                 | Station Select           | Payment                 |
| -------------------- | ------------------------ | ----------------------- |
| ![](assets/home.png) | ![](assets/stations.png) | ![](assets/payment.png) |

---

## ğŸ“„ License

MIT â€” see `LICENSE`.

---

## ğŸ™ Acknowledgments

* HCI course team and study participants
* Open source libraries used (OpenCV, MediaPipe, NumPy)
